\input{header_beamer}
\usepackage{etex}
%\include{macros}
%\documentclass[usenames,dvipsnames]{beamer}
%\usepackage{beamerthemesplit}
%\usepackage{graphics}
%\usepackage{amsmath}
%\usepackage{rotating}
%\usepackage{array}
%\usepackage{nth}
\usepackage{xcolor}
\usepackage{textcomp}
\input{matlab_setup}

\usepackage{tabularx}
\usepackage{picins}
\usepackage{tikz}
\usepackage{changepage}

\usetikzlibrary{shapes.geometric,arrows,chains,matrix,positioning,scopes,calc}
\tikzstyle{mybox} = [draw=white, rectangle]

\definecolor{camlightblue}{rgb}{0.601 , 0.8, 1}
\definecolor{camdarkblue}{rgb}{0, 0.203, 0.402}
\definecolor{camred}{rgb}{1, 0.203, 0}
\definecolor{camyellow}{rgb}{1, 0.8, 0}
\definecolor{lightblue}{rgb}{0, 0, 0.80}
\definecolor{white}{rgb}{1, 1, 1}
\definecolor{whiteblue}{rgb}{0.80, 0.80, 1}

\newcolumntype{x}[1]{>{\centering\arraybackslash\hspace{0pt}}m{#1}}
\newcommand{\tabbox}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Some look and feel definitions
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength{\columnsep}{0.03\textwidth}
\setlength{\columnseprule}{0.0018\textwidth}
\setlength{\parindent}{0.0cm}

%\include{macros}
\usepackage{preamble}
\hypersetup{colorlinks=true,citecolor=blue}
%\pdfmapfile{+sansmathaccent.map}

\title{Automatic construction and description of nonparametric models}

\author{
\includegraphics[height=0.2\textwidth]{figures/JamesLloyd3}
\qquad
\includegraphics[height=0.2\textwidth, trim=20mm 25mm 0mm 25mm, clip]{figures/david2}
\qquad
\includegraphics[height=0.2\textwidth]{figures/roger-photo}
\\
James Robert Lloyd, David Duvenaud, Roger Grosse,\\ Josh Tenenbaum, Zoubin Ghahramani
}
\institute{
%\includegraphics[width=0.4\textwidth]{figures/spiral_main}
}
%\date{}


\begin{document}

\frame[plain] {
\titlepage
}

\setbeamercolor{toc}{fg=black}

%\frame[plain] {
%\frametitle{Outline}
%\tableofcontents

%\begin{itemize} 
%	\item Motivation
%	\item Automated structure discovery in regression
%	\begin{itemize} 
%		\item Gaussian process regression
%		\item Structures expressible through kernel composition
%		\item A massive missing piece
%		\item grammar \& search over models
%		\item Examples of structures discovered
%	\end{itemize}
%	\item Automated structure discovery in matrix models
%	\begin{itemize} 
%		\item expressing models as matrix decompositions
%		\item grammar \& special cases
%		\item examples of structures discovered on images
%	\end{itemize}
%\end{itemize}   
%
%}


%\frame[plain]{
%\frametitle{Credit where credit is due}
%
%Talk based on two papers:
%	\begin{itemize}
%		\item Structure Discovery in Nonparametric Regression through Compositional Kernel Search [ICML 2013]
%		\\
%		{David Duvenaud, James Robert Lloyd, Roger Grosse, Joshua B. Tenenbaum, Zoubin Ghahramani}
%		\item Exploiting compositionality to explore a large space of model structures [UAI 2012]
%		\\
%		Roger B. Grosse, Ruslan Salakhutdinov, \\William T. Freeman, Joshua B. Tenenbaum
%	\end{itemize}
%}


\frame[plain]{
\frametitle{Motivation}
\begin{itemize} 
	\item Models today built by hand, or chosen from a fixed set.
	\begin{itemize} 
		\item Example: Scikit-learn
		\item \includegraphics[width=9cm, trim=1.39cm 15cm 35cm 0cm, clip]{figures/plot_classifier_comparison_1}
		\item \includegraphics[width=9cm, trim=35cm 15cm 1.35cm 0cm, clip]{figures/plot_classifier_comparison_1}
%		\begin{itemize} 

	\end{itemize}
\end{itemize}
}




\frame[plain]{
\frametitle{Problems with this approach}
\begin{itemize} 
	\item Building by hand requires expertise, understanding of the dataset 
	\item just being nonparametric isn't good enough
	\item can silently fail.
\end{itemize}
}



\frame[plain]{
\frametitle{Motivation}
	\begin{itemize} 
		\item Andrew Gelman asks:  How would an AI do statistics?
%				\begin{itemize} 
%			\item Propose new model
%			\item Do inference
%			\item Check model fit
%		\end{itemize}
	\item would need:
			\begin{itemize} 
			\item a language for describing arbitrarily complicated models
			\item a way to search over those models
			\item a way of checking model fit
		\end{itemize}
	\item We built such a language over regression models, a procedure to search over them, and a method to describe in english language the properties of the resulting models.
	\begin{itemize}
		\item Working on automatic model-checking.
	\end{itemize}
\end{itemize}
}


\definecolor{verylightblue}{rgb}{0.97,0.97,1}
\setlength{\fboxsep}{0pt}

\newcommand{\ltrim}{ 2 }
\newcommand{\rictrim}{ 2 }
%\newcommand{\airlinefig}[1]{\includegraphics[trim=20 0 12 20, clip, width=0.207\textwidth]{figures/#1}}
%\newcommand{\airlinefigtwo}[1]{}
\newcommand{\olduptext}[1]{\hspace{-1cm} \raisebox{ 0.8cm}{ {#1}} \hspace{-0.75cm} }
\newcommand{\uptext}[1]{\raisebox{1cm}{#1}}

\frame[plain]{
\frametitle{Example}


\begin{adjustwidth}{-1.2cm}{}
\begin{tabular}{@{}c@{}}
%\airlinefig{01-airline-months_all}&\hspace{0.6cm}\olduptext{$=$} \hspace{-0.1cm}
%\airlinefig{01-airline-months_1} & \olduptext{$+$}
%\airlinefig{01-airline-months_2} & \olduptext{$+$}
%\airlinefig{/01-airline-months_3} \\
%\hspace{-3.5mm}
%\fbox{

%\hspace{-3.5mm}
\begin{tabular}{@{}cc@{}}
%\\[-0.7em]
%\fcolorbox{blue}{white}{
\includegraphics[trim=7.8cm 14.5cm 0cm 2cm, clip, width=0.5\columnwidth]{figures/airline-pages/pg_0002-crop} 
%}
 & \uptext{$=$} \\
 entire signal & 
\end{tabular}

\\
\begin{tabular}{p{3.5cm}p{0.3cm}p{3.5cm}p{0.3cm}p{3.5cm}}
\\%[1cm]
\includegraphics[trim=0.4cm 6cm 8.4cm 2.75cm, clip, width=0.33\columnwidth]{figures/airline-pages/pg_0003-crop} & 
 \uptext{$+$}  &  
\includegraphics[trim=0.4cm 6cm 8.4cm 2.88cm, clip, width=0.33\columnwidth]{figures/airline-pages/pg_0004-crop} & 
\uptext{$+$} &  
\includegraphics[trim=0.4cm 6cm 8.4cm 2.75cm, clip, width=0.33\columnwidth]{figures/airline-pages/pg_0005-crop} \\
{\scriptsize A very smooth, monotonically increasing function }
& & 
{\scriptsize An approximately periodic function with a period of 1.0 years and with
approximately linearly increasing amplitude}
& & 
{\scriptsize An exactly periodic function with a period of 4.3 years but with linearly
increasing amplitude }
\end{tabular}
\end{tabular}

\end{adjustwidth}
}




\frame[plain]{
\frametitle{How to build a language of models?}
\begin{itemize} 
	\item We'll do this by defining a language on GP kernels
	\item Simple rules to combine them give diverse structures
\end{itemize}
}


\frame[plain]{
\frametitle{Kernel Determines Structure}
\begin{itemize} 
	\item Kernel determines almost all the properties of the prior.
	\item Many different kinds, with very different properties:
\input{tables/simple_kernels_table_v3}
\end{itemize}
}


\frame[plain]{
\frametitle{Kernels can be composed}
\begin{itemize} 
	\item Two main operations: adding, multiplying
	\input{tables/comp1}
\end{itemize}
}

\frame[plain]{
\frametitle{Kernels can be composed}
\begin{itemize} 
	\item Can be composed across multiple dimensions
	\input{tables/comp2}
\end{itemize}
}



\frame[plain]{
\frametitle{Special Cases}
\begin{center}
  \begin{tabular}{l|l}
  Bayesian linear regression & $\Lin$ \\
  %Bayesian quadratric regression & $\Lin \times \Lin$ \\
  Bayesian polynomial regression & $\Lin \times \Lin \times \ldots$\\
  Generalized Fourier decomposition & $\Per + \Per + \ldots$ \\
  Generalized additive models & $\sum_{d=1}^D \SE_d$ \\
  Automatic relevance determination & $\prod_{d=1}^D \SE_d$ \\
  Linear trend with deviations & $\Lin + \SE$ \\
  Linearly growing amplitude & $\Lin \times \SE$
  \end{tabular}
\end{center}
}


\frame[plain]{
\frametitle{Compositional Structure Search}
\begin{itemize}
	\item Define grammar over kernels:
	\begin{itemize}
		\item $ K \rightarrow K + K$ 
		\item $ K \rightarrow K \times K$ 
		\item $ K \rightarrow \{ \SE, \Lin, \Per \}$
	\end{itemize}
	\item Search the space of kernels greedily by applying production rules, checking model fit (approximate marginal likelihood).
\end{itemize}
}




\tikzset{hide on/.code={\only<#1>{\color{white}}}}

\frame[plain]{
\frametitle{Compositional Structure Search}
\hspace{-1.2cm}
\only<1>{\includegraphics[width=0.4\textwidth]{figures/11-Feb-v4-03-mauna2003-s_max_level_0/03-mauna2003-s_all_small.pdf}}
\only<2>{\includegraphics[width=0.4\textwidth]{figures/11-Feb-v4-03-mauna2003-s_max_level_1/03-mauna2003-s_all_small.pdf}}
\only<3>{\includegraphics[width=0.4\textwidth]{figures/11-Feb-v4-03-mauna2003-s_max_level_2/03-mauna2003-s_all_small.pdf}}
\only<4>{\includegraphics[width=0.4\textwidth]{figures/11-Feb-v4-03-mauna2003-s_max_level_3/03-mauna2003-s_all_small.pdf}}

\vspace{-3.5cm}
\begin{minipage}[t][14cm][t]{1.14\linewidth}
\begin{flushleft}
\hspace{5.5cm}
\vspace{-8cm}
\makebox[\textwidth][c]{
\raisebox{10cm}{
\vspace{-8cm}
\begin{tikzpicture}
[sibling distance=0.18\columnwidth,-,thick, level distance=0.13\columnwidth]
%\footnotesize
\node[shape=rectangle,draw,thick] {Start}
%\pause
  child {node {$\SE$}}
%  fill=camlightblue!30
  child {node[shape=rectangle,draw,thick] {$\RQ$}
    [sibling distance=0.16\columnwidth]
%    {\visible<2->{ child {node {\ldots}}}}
    child [hide on=-1] {node {$\SE$ + \RQ}}
    child [hide on=-1] {node {\ldots}}
    child [hide on=-1] {node[shape=rectangle,draw,thick] {$\Per + \RQ$}
      [sibling distance=0.23\columnwidth]
      child [hide on=-2] {node {$\SE + \Per + \RQ$}}
      child [hide on=-2] {node {\ldots}}
      child [hide on=-2] {node[shape=rectangle,draw,thick] {$\SE \times (\Per + \RQ)$}
        [sibling distance=0.14\columnwidth]
        child [hide on=-3] {node {\ldots}}
        child [hide on=-3] {node {\ldots}}
        child [hide on=-3] {node {\ldots}}
      }
      child [hide on=-2] {node {\ldots}}
    }
    %child {node {$\RQ \times \SE$}}
    child [hide on=-1] {node {\ldots}}
    child [hide on=-1] {node {$\Per \times \RQ$}}
  }
  child {node {$\Lin$}}
  child {node {$\Per$}}
  ;
\end{tikzpicture}}
}\end{flushleft}
\end{minipage}
\only<4>{}
}



\frame[plain]{
\frametitle{Distributivity helps Interpretability}

We can write all kernels as sums of products of base kernels:
$${\SE \times (\RQ + \Lin) = (\SE \times \RQ) + (\SE \times \Lin)}.$$

Sums of kernels are equivalent to sums of functions.

If ${f_1, f_2}$ are independent, and ${f_1 \sim \GP(\mu_1, k_1)}$, ${f_2 \sim \GP(\mu_2, k_2)}$.
Then it follows that $${(f_1 + f_2) \sim \GP(\mu_1 + \mu_2, k_1 + k_2)}$$
}

\frame[plain]{
\frametitle{Example Decomposition: Airline }
\begin{center}
  \input{figures/fig_airline.tex}
\end{center}
}


\frame[plain]{
\frametitle{Example Kernel Descriptions}
\centering
\begin{tabular}{l|l}
Product of Kernels & Description \\
\midrule
$\kPer$ & An exactly periodic function \\
$\kPer \times \kSE$ & An approximately periodic function \\
$\kPer \times \kSE \times \kLin$ & An approximately periodic function \\ &  with linearly varying amplitude \\
$\kLin$ & A linear function \\
$\kLin \times \kLin$ & A quadratic function \\
$\kPer \times \kLin \times \kLin$ & An exactly periodic function \\ & with quadratically varying amplitude\\
\end{tabular}
}


\frame[plain]{
\frametitle{This analysis was automatically generated}

\vspace{0.5\baselineskip}

\begin{center}
\fbox{\includegraphics[trim=0cm 9.5cm 0cm 0.7cm, clip, width=0.98\columnwidth]{figures/airline-pages/pg_0002-crop.pdf}}


\end{center}
}

\frame[plain]{
\frametitle{This analysis was automatically generated}

\begin{center}
\vspace{0.5\baselineskip}

\only<1>{
\fbox{\includegraphics[trim=0cm 6cm 0cm 0.9cm, clip, width=0.98\columnwidth]{figures/airline-pages/pg_0003-crop.pdf}}}

\only<2>{\fbox{\includegraphics[trim=0cm 6cm 0cm 0.0cm, clip, width=0.98\columnwidth]{figures/airline-pages/pg_0004-crop.pdf}}}

\only<3>{
\fbox{\includegraphics[trim=0cm 6cm 0cm 0.0cm, clip, width=0.98\columnwidth]{figures/airline-pages/pg_0005-crop.pdf}}}

\end{center}
}






\frame[plain]{
\frametitle{Summary}
\begin{itemize}
	\item Compositions of kernels give a language of models.
	\item Can search over models automatically.
	\item Kernels modify prior in predictable ways, allowing automatic english description of models.
\end{itemize}
	\pause
	\centering
	{
		\hfill
		Thanks!
				\hfill
	}
}



\end{document}